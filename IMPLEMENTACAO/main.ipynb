{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"figs/LogoUFSCar.jpg\" alt=\"Logo UFScar\" width=\"110\" align=\"left\"/>  <br/> <center>Universidade Federal de São Carlos (UFSCar)<br/><font size=\"4\"> Departamento de Computação, campus Sorocaba</center></font>\n",
    "</p>\n",
    "\n",
    "<font size=\"4\"><center><b>Disciplina: Aprendizado de Máquina</b></center></font>\n",
    "  \n",
    "<font size=\"3\"><center>Prof. Dr. Tiago A. Almeida</center></font>\n",
    "\n",
    "## <center>Projeto Final</center>\n",
    "\n",
    "**Aluno**: Guilherme Silva de Camargo\n",
    "\n",
    "**RA**: 792183\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise exploratória\n",
    "\n",
    "Nesta seção, deve ser feita a leitura da base de dados e todas as análises necessárias para interpretar e analisar os dados, tais como:\n",
    "* Significado de cada atributo\n",
    "* Medidas descritivas\n",
    "* Gráficos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados\n",
    "\n",
    "Nesta parte será feito o carregamento dos dados para data frames, sendo que cada arquivo será separado em uma data frame, ficando separados em dados clínicos, expressão genética, mutações gênicas e rôtulos dos dados de treinamento e teste, por fim, um data frame juntando todos os dados dos pacientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.analise_exploratoria import *\n",
    "\n",
    "FILES_DIRECTORY = \"dataset\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_dataset, df_clinical_data, df_expression_data, df_mutation_data, df_train, df_test = carregaDados(FILES_DIRECTORY)\n",
    "    \n",
    "    print(\"\\nDataset_clinical_data shape: \", df_clinical_data.shape)\n",
    "    print(\"Dataset_expression_data shape: \", df_expression_data.shape)\n",
    "    print(\"Dataset_mutation_data shape: \", df_mutation_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Significado dos atributos\n",
    "\n",
    "A base de dados contém diversos atributos, sendo necessário um bom entendimento a cerca de qual o significado de cada um, na seqûencia, uma tabela elucidando cada um dos atributos, contando com uma definição simples do significado de cada atributo para uma melhor compreensão da base de dados.\n",
    "\n",
    "|         **ATRIBUTOS**        |                     **Significado**                     |\n",
    "|:----------------------------:|:-------------------------------------------------------:|\n",
    "|         Diagnosis Age        |        Idade a qual o paciente foi diagnosticado        |\n",
    "| Bone Marrow Blast Percentage |    Porcentagem de blastos na medula óssea do paciente   |\n",
    "|        Mutation Count        |         Contador de mutações gênicas no paciente        |\n",
    "|      PB Blast Percentage     | Porcentagem de blastos em sangue periférico do paciente |\n",
    "|              WBC             |             Leucócitos no sangue do paciente            |\n",
    "|              Sex             |                     Sexo do paciente                    |\n",
    "|             Race             |                     Raça do paciente                    |\n",
    "|       Cytogenetic Info       |          Informações citogenéticas do paciente          |\n",
    "|    ELN Risk Classification   |     Classificação de risco molecular ELN do paciente    |\n",
    "|      Treatment Intensity     |          Intensidade do tratamento do paciente          |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medidas descritivas\n",
    "\n",
    "A seguir teremos três tabelas elucidando métricas para os dados clínicos, sendo uma tabela para as medidas descritivas, uma matriz de covariância, e uma matriz de correlação. Dessa forma, buscando obter uma interpretação inicial dos valores acerca da base de dados, correlação entre atributos, valores de máximo e mínimo, média, entre outras métricas. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, teremos as medidas descritivas, contendo quantidade, média, desvio padrão, valor de mínimo e máximo, 1°, 2° e 3° quartil para cada atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    descritivo = medidasDescritivas(df_clinical_data)\n",
    "    print(\"Medidas descritivas:\")\n",
    "    display(descritivo.rename(index={'mean': 'Média', 'std': 'Desvio Padrão', 'min': 'Mínimo', '25%': '1º Quartil', '50%': 'Mediana', '75%': '3º Quartil', 'max': 'Máximo', 'count': 'Quantidade'}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na sequência a matriz de correlação, procurando identificar se há uma correlação entre si dos dados clínicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"\\nMatriz de correlacao:\")\n",
    "    matCor = matrizCorrelacao(df_clinical_data)\n",
    "    display(matCor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizando esta etapa temos a matriz de covariância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"\\nMatriz de covariancia:\")\n",
    "    matCov = matrizCovariancia(df_clinical_data)\n",
    "    display(matCov)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráficos\n",
    "\n",
    "A seguir teremos gráficos de barra com os valores médios, gráficos de dispersão, boxplots e histogramas.\n",
    "\n",
    "Inicialmente, será exibido o boxplot dos atributos \"Diagnosis Age\", \"Bone Marrow Blast Percentage\", \"Mutation Count\", \"PB Blast Percentage\", \"WBC\", \"ELN Risk Classification\" pela classe \"Overral Survival Status\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "    atributosNum = [\"Diagnosis Age\", \"Bone Marrow Blast Percentage\", \"Mutation Count\", \"PB Blast Percentage\", \"WBC\", \"ELN Risk Classification\"]\n",
    "    boxplot(df_dataset, df_train, atributosNum, \"Overall Survival Status\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, os gráficos de barra com os valores médios dos atributos \"Diagnosis Age\", \"Bone Marrow Blast Percentage\", \"Mutation Count\", \"PB Blast Percentage\", \"WBC\", \"ELN Risk Classification\", \"Sex\" e \"Race\" pela classe \"Overral Survival Status\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    atributosCatNum = [\"Diagnosis Age\", \"Bone Marrow Blast Percentage\", \"Mutation Count\", \"PB Blast Percentage\", \"WBC\", \"ELN Risk Classification\", \"Sex\", \"Treatment Intensity\"]\n",
    "    graficoBarra(df_dataset, df_train, atributosCatNum, \"Overall Survival Status\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na sequência, será exibido os histogramas, esses abrangem os valores categóricos junto aos valores númericos, contando com os atributos \"Diagnosis Age\", \"Bone Marrow Blast Percentage\", \"Mutation Count\", \"PB Blast Percentage\", \"WBC\", \"ELN Risk Classification\", \"Sex\", \"Treatment Intensity\" e \"Race\", sendo esse último exibido separadamente para melhor visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    histogramaConj(df_dataset, df_train, atributosCatNum, \"Overall Survival Status\")\n",
    "    histogramaAtr(df_dataset, df_train, \"Race\", \"Overall Survival Status\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, teremos os gráficos de dispersão com a relação entre si dos seguintes atributos: \"Diagnosis Age\", \"Bone Marrow Blast Percentage\", \"Mutation Count\", \"PB Blast Percentage\" e \"WBC\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    atributos_disp = [\"Diagnosis Age\", \"Bone Marrow Blast Percentage\", \"Mutation Count\", \"PB Blast Percentage\", \"WBC\"]\n",
    "    graficoDispersao(df_dataset, df_train, atributos_disp, \"Overall Survival Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pré-processamento\n",
    "\n",
    "Nesta seção, as funções da etapa de pré-processamento dos dados devem ser implementadas e aplicadas (se necessário)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeiros pré-processamentos\n",
    "\n",
    "Primeiramente, será removido as amostras duplicadas dos data frames contendo os dados do paciente, em seguida, faremos a conversão das variáveis categóricas para valores númericos, ademais, será substituida as variáveis vazias pela média da coluna do atributo em questão, e também agruparemos os possíveis valores do atributo \"Race\", pois como visto no histograma, há valores repetidos mudando apenas letras maiúsculas ou minúsculas, esses pré-processamentos serão aplicados nesse momento no data frame contendo os valores clínicos do paciente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.preprocessamento import *\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    droparDuplicadas(df_clinical_data, df_expression_data, df_mutation_data)\n",
    "    \n",
    "    df_clinical_data = agrupaRace(df_clinical_data)\n",
    "    df_clinical_data = converteCategorias(df_clinical_data)\n",
    "    df_clinical_data = substituiNaN(df_clinical_data)\n",
    "    df_dataset_clinical_train = pd.merge(df_clinical_data, df_train, on=\"Sample ID\", how=\"right\")\n",
    "    df_dataset_clinical_test = pd.merge(df_clinical_data, df_test, on=\"Sample ID\", how=\"right\")\n",
    "    \n",
    "    print(\"\\nTamanho dos datasets clinical de treino e teste: \")\n",
    "    print(\"Treino: \", df_dataset_clinical_train.shape)\n",
    "    print(\"Teste: \", df_dataset_clinical_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuaremos com os pré-processamentos, agruparemos os dados de expressão génetica com os rótulos de treino e teste, e aplicaremos a conversão de categórias e subsituição dos valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "    df_dataset_expression_train = pd.merge(df_expression_data, df_train, on=\"Sample ID\", how=\"right\")\n",
    "    df_dataset_expression_test = pd.merge(df_expression_data, df_test, on=\"Sample ID\", how=\"right\")\n",
    "    \n",
    "    df_dataset_expression_train = converteCategorias(df_dataset_expression_train)\n",
    "    df_dataset_expression_train = substituiNaN(df_dataset_expression_train)\n",
    "    df_dataset_expression_test = converteCategorias(df_dataset_expression_test)\n",
    "    df_dataset_expression_test = substituiNaN(df_dataset_expression_test)\n",
    "    \n",
    "    print(\"Tamanho dos datasets expression de treino e teste: \")\n",
    "    print(\"Treino: \", df_dataset_expression_train.shape)\n",
    "    print(\"Teste: \", df_dataset_expression_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, faremos o mesmo processo para os dados de mutação gênica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "    df_dataset_mutation_train = pd.merge(df_mutation_data, df_train, on=\"Sample ID\", how=\"right\")\n",
    "    df_dataset_mutation_test = pd.merge(df_mutation_data, df_test, on=\"Sample ID\", how=\"right\")\n",
    "    \n",
    "    df_dataset_mutation_train = converteCategorias(df_dataset_mutation_train)\n",
    "    df_dataset_mutation_train = substituiNaN(df_dataset_mutation_train)\n",
    "    \n",
    "    df_dataset_mutation_test = converteCategorias(df_dataset_mutation_test)\n",
    "    df_dataset_mutation_test = substituiNaN(df_dataset_mutation_test)\n",
    "    \n",
    "    print(\"Tamanho dos datasets mutation de treino e teste: \")\n",
    "    print(\"Treino: \", df_dataset_mutation_train.shape)\n",
    "    print(\"Teste: \", df_dataset_mutation_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Experimento\n",
    "\n",
    "Nesta seção, o experimento deve ser conduzido, utilizando os protocolos experimentais padrões e testando diferentes modelos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na próxima etapa, converteremos os datas frames contendo as expressões géneticas, mutações gênicas e dados clínicos para matrizes, em seguida, faremos a seleção das k melhores features para cada data frame separadamente, após isso reuniremos os dados em uma única matriz, testando para diferentes k(s), assim, chegando na quantidade de features de melhor acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.experimentos import *\n",
    "\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    k_features_clinical = [2]\n",
    "    k_features_expression = [15, 18, 20, 22, 24]\n",
    "    k_features_mutation = [55, 58, 60, 62, 64]\n",
    "    \n",
    "    k_features_final = []\n",
    "    \n",
    "    value_max = 0\n",
    "    \n",
    "    for k_cli in k_features_clinical:\n",
    "        train_x_cli, train_y_cli, test_x_cli = converteSelecionaFeatures(df_dataset_clinical_train, df_dataset_clinical_test, f_classif, k_cli)\n",
    "        for k_exp in k_features_expression:\n",
    "            train_x_exp, train_y_exp, test_x_exp = converteSelecionaFeatures(df_dataset_expression_train, df_dataset_expression_test, f_classif, k_exp)\n",
    "            for k_mut in k_features_mutation:\n",
    "                train_x_mut, train_y_mut, test_x_mut = converteSelecionaFeatures(df_dataset_mutation_train, df_dataset_mutation_test, chi2, k_mut)\n",
    "                \n",
    "                train_x = np.concatenate([train_x_cli, train_x_exp, train_x_mut], axis=1)\n",
    "                train_y = train_y_cli\n",
    "                test_x = np.concatenate([test_x_cli, test_x_exp, test_x_mut], axis=1)\n",
    "                \n",
    "                data_resultado = selecionarMelhoresFeatures(train_x, train_y, 10)\n",
    "                data_resultado.to_csv(\"k_features/resultados_kClin{}_kExp{}_kMut{}.csv\".format(k_cli, k_exp, k_mut), index=False)\n",
    "                \n",
    "                value_mean = data_resultado[\"Curva ROC\"].values.mean()\n",
    "                \n",
    "                if value_mean > value_max:\n",
    "                    value_max = value_mean\n",
    "                    k_features_final = [k_cli, k_exp, k_mut]\n",
    "                    \n",
    "    print(\"Melhor combinacao de features: \")\n",
    "    print(\"\\nMelhor k para o clinical_data: \", k_features_final[0])\n",
    "    print(\"Melhor k para o expression_data: \", k_features_final[1])\n",
    "    print(\"Melhor k para o mutation_data: \", k_features_final[2])\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na próxima etapa, converteremos o data frame contendo as expressões géneticas para uma matriz, em seguida, faremos a seleção das k melhores features descobertas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':      \n",
    "    train_x_exp, train_y_exp = converteMatrix(df_dataset_expression_train)\n",
    "    test_x_exp = df_dataset_expression_test.values\n",
    "    \n",
    "    features_exp = selecionaFeaturesKBest(train_x_exp, train_y_exp, k_features_final[1], f_classif)\n",
    "    train_x_exp = train_x_exp[:, features_exp]\n",
    "    test_x_exp = test_x_exp[:, features_exp]\n",
    "    \n",
    "    print(\"Features selecionadas do genetic_expression:\")\n",
    "    print(df_dataset_expression_train.columns[features_exp].values)\n",
    "    \n",
    "    print(\"\\nTamanho da matriz expression de treino e teste: \")\n",
    "    print(\"Treino: \", train_x_exp.shape)\n",
    "    print(\"Teste: \", test_x_exp.shape) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetiremos o processo para o data frame contendo os dados das mutações gênicas, porém utilizando a função \"chi2\" ao invés de \"f_classif\" como ocorre nas outras duas seleções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':      \n",
    "    train_x_mut, train_y_mut = converteMatrix(df_dataset_mutation_train)\n",
    "    test_x_mut = df_dataset_mutation_test.values\n",
    "    \n",
    "    features_mut = selecionaFeaturesKBest(train_x_mut, train_y_mut, k_features_final[2], chi2)\n",
    "    train_x_mut = train_x_mut[:, features_mut]\n",
    "    test_x_mut = test_x_mut[:, features_mut]\n",
    "    \n",
    "    print(\"Features selecionadas do genetic_mutation: \")\n",
    "    print(df_dataset_mutation_train.columns[features_mut].values)\n",
    "    \n",
    "    print(\"\\nTamanho da matriz mutation de treino e teste: \")\n",
    "    print(\"Treino: \", train_x_mut.shape)\n",
    "    print(\"Teste: \", test_x_mut.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, faremos o mesmo processo para os data frame contendo os dados clínicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':             \n",
    "    train_x_cli, train_y_cli = converteMatrix(df_dataset_clinical_train)\n",
    "    test_x_cli = df_dataset_clinical_test.values\n",
    "    \n",
    "    features_clin = selecionaFeaturesKBest(train_x_cli, train_y_cli, k_features_final[0], f_classif)\n",
    "    train_x_cli = train_x[:, features_clin]\n",
    "    test_x_cli = test_x[:, features_clin]\n",
    "    \n",
    "    print(\"Features selecionadas do clinical_data: \")\n",
    "    print(df_dataset_clinical_train.columns[features_clin].values)\n",
    "    \n",
    "    print(\"Tamanho da matriz clinical de treino e teste: \")\n",
    "    print(\"Treino: \", train_x_cli.shape)\n",
    "    print(\"Teste: \", test_x_cli.shape) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupa todos os dados selecionados em somente uma matriz, finalizando a etapa de pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "if __name__ == '__main__':  \n",
    "    train_x = np.concatenate((train_x_exp, train_x_mut, train_x_cli), axis=1)\n",
    "    test_x = np.concatenate((test_x_exp, test_x_mut, test_x_cli), axis=1)\n",
    "    train_y = train_y_exp\n",
    "        \n",
    "    print(\"Tamanho da matriz de treino e teste: \")\n",
    "    print(\"Treino: \", train_x.shape)\n",
    "    print(\"Teste: \", test_x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proxima etapa, treinamos com os seguintes algoritmos: K-vizinhos mais próximos (KNN), Naive Bays, Regressão Logistica, Rede neural, Máquina de Vetores de Suporte e Floresta Aleatoria.\n",
    "\n",
    "Primeiro, testaremos para o classificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import *\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "    df_dataModel = pd.DataFrame(columns=[\"Modelo\", \"Acuracia\", \"Desvio Padrao\", \"Curva ROC\", \"F1-score\", \"Recall\", \"Precisao\", \"Melhores Parametros\"])\n",
    "    nfolds = 10\n",
    "\n",
    "    params_knn = {\"n_neighbors\": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]}\n",
    "    acc_knn, std_knn, roc_knn, recall_knn, pre_knn, f1_knn, best_param_knn, model_knn = knn(train_x, train_y, nfolds, params_knn)\n",
    "    df = pd.DataFrame({\"Modelo\": \"KNN\", \"Acuracia\": acc_knn, \"Desvio Padrao\": std_knn, \"Curva ROC\": roc_knn, \"F1-score\": f1_knn, \"Recall\": recall_knn, \"Precisao\": pre_knn, \"Melhores Parametros\": [best_param_knn]}, index=[0])\n",
    "    df_dataModel = pd.concat([df_dataModel, df], ignore_index=True)\n",
    "    \n",
    "    print(\"-------------------KNN-------------------\")\n",
    "    print(\"Acuracia: \", acc_knn)\n",
    "    print(\"Desvio Padrao: \", std_knn)\n",
    "    print(\"Curva ROC: \", roc_knn)\n",
    "    print(\"Recall: \", recall_knn)\n",
    "    print(\"Precisao: \", pre_knn)\n",
    "    print(\"F1-score: \", f1_knn)\n",
    "    print(\"Melhores Parametros: \", best_param_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    # Naive Bayes\n",
    "    params_nb = {\"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]}\n",
    "    acc_nb, std_nb, roc_nb, recall_nb, pre_nb, f1_nb, best_param_nb, model_nb = naiveBayes(train_x, train_y, nfolds, params_nb)\n",
    "    df = pd.DataFrame({\"Modelo\": \"Naive Bayes\", \"Acuracia\": acc_nb, \"Desvio Padrao\": std_nb, \"Curva ROC\": roc_nb, \"F1-score\": f1_nb, \"Recall\": recall_nb, \"Precisao\": pre_nb, \"Melhores Parametros\": [best_param_nb]}, index=[0])\n",
    "    df_dataModel = pd.concat([df_dataModel, df], ignore_index=True)\n",
    "    \n",
    "    print(\"-------------------Naive Bayes-------------------\")\n",
    "    print(\"Acuracia: \", acc_nb)\n",
    "    print(\"Desvio Padrao: \", std_nb)\n",
    "    print(\"Curva ROC: \", roc_nb)\n",
    "    print(\"Recall: \", recall_nb)\n",
    "    print(\"Precisao: \", pre_nb)\n",
    "    print(\"F1-score: \", f1_nb)\n",
    "    print(\"Melhores Parametros: \", best_param_nb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classicador Regressão Logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "\n",
    "if __name__ == '__main__': \n",
    "        # Regressao Logistica\n",
    "        params_rl = {\"C\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \"max_iter\": [5000]}\n",
    "        acc_rl, std_rl, roc_rl, recall_rl, pre_rl, f1_rl, best_param_rl, model_rl = regressaoLogistica(train_x, train_y, nfolds, params_rl)\n",
    "        df = pd.DataFrame({\"Modelo\": \"Regressao Logistica\", \"Acuracia\": acc_rl, \"Desvio Padrao\": std_rl, \"Curva ROC\": roc_rl, \"F1-score\": f1_rl, \"Recall\": recall_rl, \"Precisao\": pre_rl, \"Melhores Parametros\": [best_param_rl]}, index=[0])\n",
    "        df_dataModel = pd.concat([df_dataModel, df], ignore_index=True) \n",
    "\n",
    "        print(\"-------------------Regressao Logistica-------------------\")\n",
    "        print(\"Acuracia: \", acc_rl)\n",
    "        print(\"Desvio Padrao: \", std_rl)\n",
    "        print(\"Curva ROC: \", roc_rl)\n",
    "        print(\"Recall: \", recall_rl)\n",
    "        print(\"Precisao: \", pre_rl)\n",
    "        print(\"F1-score: \", f1_rl)\n",
    "        print(\"Melhores Parametros: \", best_param_rl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador Rede Neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import *\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    # Redes Neurais\n",
    "    params_rn = {\"hidden_layer_sizes\": [(10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60), (70, 70), (80, 80), (90, 90), (100, 100)], \"max_iter\": [5000]}\n",
    "    acc_rn, std_rn, roc_rn, recall_rn, pre_rn, f1_rn, best_param_rn, model_rn = redesNeurais(train_x, train_y, nfolds, params_rn)\n",
    "    df = pd.DataFrame({\"Modelo\": \"Redes Neurais\", \"Acuracia\": acc_rn, \"Desvio Padrao\": std_rn, \"Curva ROC\": roc_rn, \"F1-score\": f1_rn, \"Recall\": recall_rn, \"Precisao\": pre_rn, \"Melhores Parametros\": [best_param_rn]}, index=[0])\n",
    "    df_dataModel = pd.concat([df_dataModel, df], ignore_index=True)\n",
    "    \n",
    "    print(\"-------------------Redes Neurais-------------------\")\n",
    "    print(\"Acuracia: \", acc_rn)\n",
    "    print(\"Desvio Padrao: \", std_rn)\n",
    "    print(\"Curva ROC: \", roc_rn)\n",
    "    print(\"Recall: \", recall_rn)\n",
    "    print(\"Precisao: \", pre_rn)\n",
    "    print(\"F1-score: \", f1_rn)\n",
    "    print(\"Melhores Parametros: \", best_param_rn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador Máquina de Vetores de Suporte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import *\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    # Máquina de Vetores de Suporte\n",
    "    params_svm = {\"C\": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "    acc_svm, std_svm, roc_svm, recall_svm, pre_svm, f1_svm, best_param_svm, model_svm = maquinaVetoresSuporte(train_x, train_y, nfolds, params_svm)\n",
    "    df = pd.DataFrame({\"Modelo\": \"Maquina de Vetores de Suporte\", \"Acuracia\": acc_svm, \"Desvio Padrao\": std_svm, \"Curva ROC\": roc_svm, \"F1-score\": f1_svm, \"Recall\": recall_svm, \"Precisao\": pre_svm, \"Melhores Parametros\": [best_param_svm]}, index=[0])\n",
    "    df_dataModel = pd.concat([df_dataModel, df], ignore_index=True)\n",
    "    \n",
    "    print(\"-------------------Maquina de Vetores de Suporte-------------------\")\n",
    "    print(\"Acuracia: \", acc_svm)\n",
    "    print(\"Desvio Padrao: \", std_svm)\n",
    "    print(\"Curva ROC: \", roc_svm)\n",
    "    print(\"Recall: \", recall_svm)\n",
    "    print(\"Precisao: \", pre_svm)\n",
    "    print(\"F1-score: \", f1_svm)\n",
    "    print(\"Melhores Parametros: \", best_param_svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador Floresta Aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    # Floresta Aleatória\n",
    "    params_fa = {\"n_estimators\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
    "    acc_fa, std_fa, roc_fa, recall_fa, pre_fa, f1_fa, best_param_fa, model_fa = florestaAleatoria(train_x, train_y, nfolds, params_fa)\n",
    "    df = pd.DataFrame({\"Modelo\": \"Floresta Aleatoria\", \"Acuracia\": acc_fa, \"Desvio Padrao\": std_fa, \"Curva ROC\": roc_fa, \"F1-score\": f1_fa, \"Recall\": recall_fa, \"Precisao\": pre_fa, \"Melhores Parametros\": [best_param_fa]}, index=[0])\n",
    "    df_dataModel = pd.concat([df_dataModel, df], ignore_index=True)\n",
    "    \n",
    "    print(\"-------------------Floresta Aleatoria-------------------\")\n",
    "    print(\"Acuracia: \", acc_fa)\n",
    "    print(\"Desvio Padrao: \", std_fa)\n",
    "    print(\"Curva ROC: \", roc_fa)\n",
    "    print(\"Recall: \", recall_fa)\n",
    "    print(\"Precisao: \", pre_fa)\n",
    "    print(\"F1-score: \", f1_fa)\n",
    "    print(\"Melhores Parametros: \", best_param_fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Análise dos Resultados\n",
    "\n",
    "Nesta seção, os resultados devem ser exibidos através de tabelas e gráficos, comparados e profundamente analisados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exibiremos os resultados iniciais para todos os classificadores testados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.analise_resultados import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df_dataModel = df_dataModel.sort_values(by=\"Acuracia\", ascending=False).reset_index(drop=True)\n",
    "    display(df_dataModel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora teremos mais dados referentes aos resultados contando com as Curvas de Aprendizados e de Validação, Curva ROC, Curva de Precisão x Recall e Matriz de confusão e novamente as métricas, porém agora os dados serão treinados com 80% da base para treino e 20% para testes.\n",
    "\n",
    "Resultados para o KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = KNeighborsClassifier(**best_param_knn)\n",
    "    plotaResultados(\"KNN\", model, train_x, train_y, \"n_neighbors\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = GaussianNB(**best_param_nb)\n",
    "    plotaResultados(\"Naive Bayes\", model, train_x, train_y, \"var_smoothing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados Regressão Logistica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = LogisticRegression(**best_param_rl)\n",
    "    plotaResultados(\"Regressao Logistica\", model, train_x, train_y, \"C\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados Redes Neurais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = MLPClassifier(**best_param_rn)\n",
    "    plotaResultados(\"Redes Neurais\", model, train_x, train_y, \"hidden_layer_sizes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados Máquinas de Vetores de Suporte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = SVC(**best_param_svm)\n",
    "    plotaResultados(\"Maquina de Vetores de Suporte\", model, train_x, train_y, \"C\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados Floresta Aleatoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = RandomForestClassifier(**best_param_fa)\n",
    "    plotaResultados(\"Floresta Aleatoria\", model, train_x, train_y, \"n_estimators\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, utiliza o melhor modelo manualmente para predizer a classe das amostras de teste que serão submetidas no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = LogisticRegression(**best_param_rl)\n",
    "    model.fit(train_x, train_y)\n",
    "    y_pred = model.predict_proba(test_x)\n",
    "    df_submission = pd.DataFrame({\"Id\": df_test.index, \"Predicted\": y_pred[:, 1]})\n",
    "    df_submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Resultado salvo com sucesso!\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ced987a247890006fadb174404bf884c2606133e9ca5a8bdda00b49ca7b4dc36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
